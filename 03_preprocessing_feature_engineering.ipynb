{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e289f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data loaded from step2.pkl: (7953, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load cleaned data from previous notebook using pickle\n",
    "with open('step2.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "print(\"Cleaned data loaded from step2.pkl:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b254e",
   "metadata": {},
   "source": [
    "## Categorical Encoding for Machine Learning\n",
    "To prepare categorical features for machine learning algorithms, we apply encoding techniques:\n",
    "- **One-Hot Encoding:** Converts each category value into a new binary column. Used for 'brand', 'category_code', and 'event_type'.\n",
    "- **Label Encoding:** Assigns each unique category value an integer label. Useful for algorithms that can interpret integer values as categories.\n",
    "\n",
    "These encodings transform categorical variables into a format suitable for clustering and other ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63d61d",
   "metadata": {},
   "source": [
    "### Example: One-Hot Encoding\n",
    "- **Input:** ['red', 'green', 'blue']\n",
    "- **Output:**\n",
    "    | red | green | blue |\n",
    "    |-----|-------|------|\n",
    "    |  1  |   0   |  0   |\n",
    "    |  0  |   1   |  0   |\n",
    "    |  0  |   0   |  1   |\n",
    "One-Hot Encoding is preferred for clustering and most ML algorithms, as it avoids implying any order or priority among categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe719ac4",
   "metadata": {},
   "source": [
    "## Feature Scaling for Machine Learning\n",
    "Feature scaling is an essential preprocessing step for numeric columns (such as 'price') before clustering. We use StandardScaler to standardize numeric features to have mean 0 and variance 1. This ensures that all features contribute equally to distance-based algorithms like KMeans, preventing features with larger scales from dominating the clustering process.\n",
    "\n",
    "In our pipeline, StandardScaler is applied to numeric columns automatically before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58286d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40fd0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "categorical_cols = ['brand', 'category_code', 'event_type']\n",
    "numeric_cols = ['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1114d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: OneHot for categorical, Scale for numeric\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "X = preprocessor.fit_transform(df[categorical_cols + numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd16b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline: Preprocessing + Clustering\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('cluster', KMeans(n_clusters=4, random_state=42))\n",
    " ])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(df[categorical_cols + numeric_cols])\n",
    "\n",
    "# Predict clusters\n",
    "df['cluster'] = pipeline.predict(df[categorical_cols + numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f80089",
   "metadata": {},
   "source": [
    "## Create Customer-Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4c1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_features = df.groupby('user_id').agg({\n",
    "    'price': ['sum', 'mean', 'count'],\n",
    "    'event_type': 'nunique',\n",
    "    'category_code': 'nunique',\n",
    "    'brand': 'nunique'\n",
    "})\n",
    "customer_features.columns = ['total_spend', 'avg_spend', 'purchase_count', 'event_type_count', 'category_count', 'brand_count']\n",
    "customer_features = customer_features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e77582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved as step3.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data and customer features for next notebook using pickle\n",
    "import pickle\n",
    "\n",
    "# Save all data using pickle\n",
    "data_bundle = {\n",
    "    'X': X,\n",
    "    'preprocessor': preprocessor,\n",
    "    'customer_features': customer_features,\n",
    "    'df': df\n",
    "}\n",
    "\n",
    "with open('step3.pkl', 'wb') as f:\n",
    "    pickle.dump(data_bundle, f)\n",
    "\n",
    "print(\"Preprocessed data saved as step3.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
