{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e289f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data loaded from Pickle Files/step2.pkl: (8536, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load cleaned data from previous notebook using pickle\n",
    "with open('Pickle Files/step2.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "print(\"Cleaned data loaded from Pickle Files/step2.pkl:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b254e",
   "metadata": {},
   "source": [
    "## Categorical Encoding for Machine Learning\n",
    "To prepare categorical features for machine learning algorithms, we apply encoding techniques:\n",
    "- **One-Hot Encoding:** Converts each category value into a new binary column. Used for 'brand', 'category_code', and 'event_type'.\n",
    "- **Label Encoding:** Assigns each unique category value an integer label. Useful for algorithms that can interpret integer values as categories.\n",
    "\n",
    "These encodings transform categorical variables into a format suitable for clustering and other ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63d61d",
   "metadata": {},
   "source": [
    "### Example: One-Hot Encoding\n",
    "- **Input:** ['red', 'green', 'blue']\n",
    "- **Output:**\n",
    "    | red | green | blue |\n",
    "    |-----|-------|------|\n",
    "    |  1  |   0   |  0   |\n",
    "    |  0  |   1   |  0   |\n",
    "    |  0  |   0   |  1   |\n",
    "One-Hot Encoding is preferred for clustering and most ML algorithms, as it avoids implying any order or priority among categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe719ac4",
   "metadata": {},
   "source": [
    "## Feature Scaling for Machine Learning\n",
    "Feature scaling is an essential preprocessing step for numeric columns (such as 'price') before clustering. We use StandardScaler to standardize numeric features to have mean 0 and variance 1. This ensures that all features contribute equally to distance-based algorithms like KMeans, preventing features with larger scales from dominating the clustering process.\n",
    "\n",
    "In our pipeline, StandardScaler is applied to numeric columns automatically before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58286d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40fd0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "categorical_cols = ['brand', 'category_code', 'event_type']\n",
    "numeric_cols = ['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1114d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: OneHot for categorical, Scale for numeric\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', StandardScaler(), numeric_cols)\n",
    "])\n",
    "X = preprocessor.fit_transform(df[categorical_cols + numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd16b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline: Preprocessing + Clustering\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('cluster', KMeans(n_clusters=4, random_state=42))\n",
    " ])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(df[categorical_cols + numeric_cols])\n",
    "\n",
    "# Predict clusters\n",
    "df['cluster'] = pipeline.predict(df[categorical_cols + numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f112419",
   "metadata": {},
   "source": [
    "## Browsing Patterns Analysis\n",
    "Analyze customer browsing behavior to understand user engagement patterns:\n",
    "- **Browsing-to-Purchase Ratio:** How many views/carts lead to actual purchases\n",
    "- **Session Activity:** Number of actions per session\n",
    "- **Event Funnel:** View ‚Üí Cart ‚Üí Purchase conversion rates\n",
    "- **Category/Brand Exploration:** Diversity of browsing vs purchasing behavior\n",
    "\n",
    "These patterns help identify different customer segments like window shoppers, decisive buyers, and exploratory users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6667bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browsing patterns calculated: (2436, 12)\n"
     ]
    }
   ],
   "source": [
    "# Calculate browsing patterns for each user\n",
    "browsing_patterns = df.groupby('user_id').agg({\n",
    "    'event_type': ['count', lambda x: (x == 'view').sum(), \n",
    "                   lambda x: (x == 'cart').sum(), \n",
    "                   lambda x: (x == 'purchase').sum()],\n",
    "    'user_session': 'nunique',\n",
    "    'category_code': 'nunique',\n",
    "    'brand': 'nunique'\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "browsing_patterns.columns = ['total_events', 'views', 'carts', 'purchases', \n",
    "                            'unique_sessions', 'categories_browsed', 'brands_browsed']\n",
    "\n",
    "# Calculate browsing ratios and patterns\n",
    "browsing_patterns['view_to_purchase_ratio'] = browsing_patterns['views'] / (browsing_patterns['purchases'] + 1)\n",
    "browsing_patterns['cart_to_purchase_ratio'] = browsing_patterns['carts'] / (browsing_patterns['purchases'] + 1)\n",
    "browsing_patterns['events_per_session'] = browsing_patterns['total_events'] / browsing_patterns['unique_sessions']\n",
    "browsing_patterns['purchase_conversion_rate'] = browsing_patterns['purchases'] / browsing_patterns['total_events']\n",
    "\n",
    "browsing_patterns = browsing_patterns.reset_index()\n",
    "print(\"Browsing patterns calculated:\", browsing_patterns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4813884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session duration metrics calculated: (2436, 6)\n"
     ]
    }
   ],
   "source": [
    "# Calculate session duration for each user\n",
    "# Convert event_time to datetime if not already done\n",
    "df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "\n",
    "# Calculate session duration metrics\n",
    "session_duration = df.groupby(['user_id', 'user_session']).agg({\n",
    "    'event_time': ['min', 'max', 'count']\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "session_duration.columns = ['session_start', 'session_end', 'events_in_session']\n",
    "\n",
    "# Calculate duration in minutes for each session\n",
    "session_duration['session_duration_minutes'] = (\n",
    "    session_duration['session_end'] - session_duration['session_start']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Aggregate session duration metrics per user\n",
    "user_session_metrics = session_duration.groupby('user_id').agg({\n",
    "    'session_duration_minutes': ['mean', 'sum', 'max', 'count'],\n",
    "    'events_in_session': 'mean'\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "user_session_metrics.columns = ['avg_session_duration', 'total_session_time', \n",
    "                               'max_session_duration', 'session_count', 'avg_events_per_session']\n",
    "\n",
    "user_session_metrics = user_session_metrics.reset_index()\n",
    "print(\"Session duration metrics calculated:\", user_session_metrics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fdc139",
   "metadata": {},
   "source": [
    "## Spending Behavior Analysis\n",
    "Analyze customer spending patterns to understand purchase behavior:\n",
    "- **Total and Average Spend:** Overall spending power and typical transaction size\n",
    "- **Purchase Frequency:** How often customers make purchases\n",
    "- **Spending Consistency:** Variance in spending amounts\n",
    "- **Price Sensitivity:** Range of prices customers engage with\n",
    "\n",
    "These metrics help identify high-value customers, frequent buyers, and price-sensitive segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64287393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spending behavior calculated: (87, 10)\n"
     ]
    }
   ],
   "source": [
    "# Calculate spending behavior patterns for each user\n",
    "spending_behavior = df[df['event_type'] == 'purchase'].groupby('user_id').agg({\n",
    "    'price': ['sum', 'mean', 'std', 'min', 'max', 'count']\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "spending_behavior.columns = ['total_spend', 'avg_spend', 'spend_std', \n",
    "                           'min_spend', 'max_spend', 'purchase_count']\n",
    "\n",
    "# Calculate additional spending metrics\n",
    "spending_behavior['spend_range'] = spending_behavior['max_spend'] - spending_behavior['min_spend']\n",
    "spending_behavior['spend_consistency'] = spending_behavior['spend_std'] / (spending_behavior['avg_spend'] + 1)\n",
    "spending_behavior['spending_per_day'] = spending_behavior['total_spend'] / 30  # Assuming 30-day period\n",
    "\n",
    "# Fill NaN values for users with no purchases\n",
    "spending_behavior = spending_behavior.fillna(0)\n",
    "spending_behavior = spending_behavior.reset_index()\n",
    "print(\"Spending behavior calculated:\", spending_behavior.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23673c",
   "metadata": {},
   "source": [
    "## Comprehensive Customer Features\n",
    "Combine **Purchase History**, **Browsing Patterns**, and **Spending Behavior** into a single customer dataset ready for clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b02b184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ALL ENGINEERED FEATURES COMPLETE:\n",
      "üìä Purchase History: Total spend, transaction patterns, frequency\n",
      "üîç Browsing Patterns: View-to-purchase ratios, session activity, conversion rates\n",
      "üí∞ Spending Behavior: Spending consistency, price sensitivity, purchase patterns\n",
      "‚è∞ Session Duration: Average session time, total engagement time, session patterns\n",
      "\n",
      "Final dataset shape: (2436, 32)\n",
      "\n",
      "‚úÖ Feature Engineering Complete: Purchase frequency, browsing-to-purchase ratio, session duration, and average spend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>total_events</th>\n",
       "      <th>views</th>\n",
       "      <th>carts</th>\n",
       "      <th>purchases</th>\n",
       "      <th>unique_sessions</th>\n",
       "      <th>categories_browsed</th>\n",
       "      <th>brands_browsed</th>\n",
       "      <th>view_to_purchase_ratio</th>\n",
       "      <th>cart_to_purchase_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>total_session_time</th>\n",
       "      <th>max_session_duration</th>\n",
       "      <th>session_count</th>\n",
       "      <th>avg_events_per_session</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>avg_transaction</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>event_types_used</th>\n",
       "      <th>categories_purchased</th>\n",
       "      <th>brands_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>474832046.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.71</td>\n",
       "      <td>102.710000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474967396.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1343.52</td>\n",
       "      <td>268.704000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>477121012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.39</td>\n",
       "      <td>179.390000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>479233261.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1789.71</td>\n",
       "      <td>255.672857</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>485580346.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>322.91</td>\n",
       "      <td>322.910000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  total_events  views  carts  purchases  unique_sessions  \\\n",
       "0  474832046.0             1      1      0          0                1   \n",
       "1  474967396.0             5      5      0          0                1   \n",
       "2  477121012.0             1      1      0          0                1   \n",
       "3  479233261.0             7      7      0          0                1   \n",
       "4  485580346.0             1      1      0          0                1   \n",
       "\n",
       "   categories_browsed  brands_browsed  view_to_purchase_ratio  \\\n",
       "0                   1               1                     1.0   \n",
       "1                   1               3                     5.0   \n",
       "2                   1               1                     1.0   \n",
       "3                   2               2                     7.0   \n",
       "4                   1               1                     1.0   \n",
       "\n",
       "   cart_to_purchase_ratio  ...  total_session_time  max_session_duration  \\\n",
       "0                     0.0  ...            0.000000              0.000000   \n",
       "1                     0.0  ...            2.533333              2.533333   \n",
       "2                     0.0  ...            0.000000              0.000000   \n",
       "3                     0.0  ...            1.083333              1.083333   \n",
       "4                     0.0  ...            0.000000              0.000000   \n",
       "\n",
       "   session_count  avg_events_per_session  total_revenue  avg_transaction  \\\n",
       "0              1                     1.0         102.71       102.710000   \n",
       "1              1                     5.0        1343.52       268.704000   \n",
       "2              1                     1.0         179.39       179.390000   \n",
       "3              1                     7.0        1789.71       255.672857   \n",
       "4              1                     1.0         322.91       322.910000   \n",
       "\n",
       "   total_transactions  event_types_used  categories_purchased  \\\n",
       "0                   1                 1                     1   \n",
       "1                   5                 1                     1   \n",
       "2                   1                 1                     1   \n",
       "3                   7                 1                     2   \n",
       "4                   1                 1                     1   \n",
       "\n",
       "   brands_purchased  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 1  \n",
       "3                 2  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all customer features: Purchase History + Browsing Patterns + Spending Behavior + Session Duration\n",
    "customer_features_comprehensive = browsing_patterns.merge(spending_behavior, on='user_id', how='outer')\n",
    "customer_features_comprehensive = customer_features_comprehensive.merge(user_session_metrics, on='user_id', how='outer')\n",
    "\n",
    "# Add purchase history features from original data\n",
    "purchase_history = df.groupby('user_id').agg({\n",
    "    'price': ['sum', 'mean', 'count'],\n",
    "    'event_type': 'nunique',\n",
    "    'category_code': 'nunique',\n",
    "    'brand': 'nunique'\n",
    "})\n",
    "purchase_history.columns = ['total_revenue', 'avg_transaction', 'total_transactions', \n",
    "                           'event_types_used', 'categories_purchased', 'brands_purchased']\n",
    "purchase_history = purchase_history.reset_index()\n",
    "\n",
    "# Final comprehensive customer features\n",
    "customer_features_final = customer_features_comprehensive.merge(purchase_history, on='user_id', how='outer')\n",
    "customer_features_final = customer_features_final.fillna(0)\n",
    "\n",
    "print(\"‚úÖ ALL ENGINEERED FEATURES COMPLETE:\")\n",
    "print(\"üìä Purchase History: Total spend, transaction patterns, frequency\")\n",
    "print(\"üîç Browsing Patterns: View-to-purchase ratios, session activity, conversion rates\")\n",
    "print(\"üí∞ Spending Behavior: Spending consistency, price sensitivity, purchase patterns\")\n",
    "print(\"‚è∞ Session Duration: Average session time, total engagement time, session patterns\")\n",
    "print(f\"\\nFinal dataset shape: {customer_features_final.shape}\")\n",
    "print(\"\\n‚úÖ Feature Engineering Complete: Purchase frequency, browsing-to-purchase ratio, session duration, and average spend\")\n",
    "customer_features_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e77582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Comprehensive preprocessed data saved as Pickle Files/step3.pkl\n",
      "üì¶ Includes: Purchase History + Browsing Patterns + Spending Behavior\n",
      "üéØ Ready for K-Means clustering analysis\n",
      "\n",
      "üì¶ Includes: Purchase History + Browsing Patterns + Spending Behavior\n",
      "üéØ Ready for K-Means clustering analysis\n"
     ]
    }
   ],
   "source": [
    "# Save comprehensive preprocessed data for next notebook using pickle\n",
    "import pickle\n",
    "\n",
    "# Save all data including comprehensive customer features\n",
    "data_bundle = {\n",
    "    'X': X,\n",
    "    'preprocessor': preprocessor,\n",
    "    'customer_features_final': customer_features_final,\n",
    "    'browsing_patterns': browsing_patterns,\n",
    "    'spending_behavior': spending_behavior,\n",
    "    'purchase_history': purchase_history,\n",
    "    'df': df\n",
    "}\n",
    "\n",
    "with open('Pickle Files/step3.pkl', 'wb') as f:\n",
    "    pickle.dump(data_bundle, f)\n",
    "\n",
    "print(\"‚úÖ Comprehensive preprocessed data saved as Pickle Files/step3.pkl\")\n",
    "print(\"üì¶ Includes: Purchase History + Browsing Patterns + Spending Behavior\")\n",
    "print(\"üéØ Ready for K-Means clustering analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
